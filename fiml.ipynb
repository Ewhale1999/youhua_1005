{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936775b5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ===== REPLACE EVERYTHING ABOVE YOUR OLD CLASS WITH THIS BLOCK =====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "class FIMLMissing:\n",
    "    \"\"\"\n",
    "    FIML (Full Information Maximum Likelihood) linear regression with missing data\n",
    "    under a joint multivariate normal (X, y). We estimate the joint mean vector\n",
    "    and covariance matrix using all partially observed rows, then derive the\n",
    "    conditional expectation E[y|X] = beta_0 + X @ beta from the joint moments.\n",
    "\n",
    "    性能关键点（已内置）：\n",
    "    - 预计算“缺失模式分组”，每种观测列组合只做一次 Cholesky 分解；\n",
    "    - 组内批量求解二次型，避免 Python for 循环（完全向量化）。\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # 回归系数\n",
    "        self.beta_0 = None\n",
    "        self.beta_coeffs = None\n",
    "\n",
    "        # 估计得到的联合分布参数\n",
    "        self.est_mu = None          # (p+1,)\n",
    "        self.est_sigma = None       # (p+1, p+1)\n",
    "\n",
    "        # 训练时的列名（X 的列顺序 + y 名）\n",
    "        self.feature_names = None\n",
    "        self.target_name = None\n",
    "\n",
    "        # FIML 过程中缓存的数据与分组（用于加速）\n",
    "        self._X_joint = None\n",
    "        self._mask_groups = None    # list of (rows_idx, cols_obs)\n",
    "\n",
    "    # --------- 工具函数：协方差上三角展开/重构 ---------\n",
    "    @staticmethod\n",
    "    def _flatten_sigma_upper(S):\n",
    "        n = S.shape[0]\n",
    "        out = []\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                out.append(S[i, j])\n",
    "        return np.asarray(out)\n",
    "\n",
    "    @staticmethod\n",
    "    def _unflatten_sigma_upper(elems, n):\n",
    "        S = np.zeros((n, n))\n",
    "        k = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i, n):\n",
    "                S[i, j] = elems[k]\n",
    "                S[j, i] = elems[k]\n",
    "                k += 1\n",
    "        return S\n",
    "\n",
    "    # --------- 预计算：按缺失模式分组 ---------\n",
    "    @staticmethod\n",
    "    def _build_mask_groups(X_joint):\n",
    "        \"\"\"\n",
    "        X_joint: (N, d) with NaNs for missing\n",
    "        return: list of (rows_idx, cols_obs)\n",
    "        \"\"\"\n",
    "        mask = ~np.isnan(X_joint)               # True 表示该列有观测\n",
    "        # 用 packbits 压缩每行布尔向量，作为键\n",
    "        keys = np.packbits(mask, axis=1)\n",
    "        row_keys = [k.tobytes() for k in keys]\n",
    "\n",
    "        groups_dict = {}\n",
    "        for i, k in enumerate(row_keys):\n",
    "            if k not in groups_dict:\n",
    "                cols = np.where(mask[i])[0]\n",
    "                groups_dict[k] = {\"rows\": [], \"cols\": cols}\n",
    "            groups_dict[k][\"rows\"].append(i)\n",
    "\n",
    "        groups = [(np.asarray(v[\"rows\"], dtype=int), v[\"cols\"])\n",
    "                  for v in groups_dict.values()]\n",
    "        return groups\n",
    "\n",
    "    # --------- 目标函数：负对数似然（按分组批量计算） ---------\n",
    "    def _neg_log_likelihood(self, params_flat, n_vars):\n",
    "        \"\"\"\n",
    "        params_flat = [mu(0:n_vars), Sigma_upper_tri_flat]\n",
    "        使用 self._X_joint 与 self._mask_groups（均由 fit() 预先缓存）\n",
    "        返回：负对数似然\n",
    "        \"\"\"\n",
    "        mu = params_flat[:n_vars]\n",
    "        sigma_elems = params_flat[n_vars:]\n",
    "        Sigma = self._unflatten_sigma_upper(sigma_elems, n_vars)\n",
    "\n",
    "        # 轻微数值稳定处理：必要时抖动\n",
    "        try:\n",
    "            np.linalg.cholesky(Sigma)\n",
    "        except np.linalg.LinAlgError:\n",
    "            Sigma = Sigma + np.eye(n_vars) * 1e-6\n",
    "\n",
    "        X = self._X_joint\n",
    "        groups = self._mask_groups\n",
    "        if X is None or groups is None:\n",
    "            raise RuntimeError(\"Internal state not prepared. Call fit() first.\")\n",
    "\n",
    "        total_loglik = 0.0\n",
    "        const_log2pi = np.log(2.0 * np.pi)\n",
    "\n",
    "        for rows_idx, cols_obs in groups:\n",
    "            if len(cols_obs) == 0 or len(rows_idx) == 0:\n",
    "                continue\n",
    "\n",
    "            mu_sub = mu[cols_obs]\n",
    "            Sigma_sub = Sigma[np.ix_(cols_obs, cols_obs)]\n",
    "\n",
    "            # 该模式只做一次 Cholesky\n",
    "            try:\n",
    "                L = np.linalg.cholesky(Sigma_sub)\n",
    "            except np.linalg.LinAlgError:\n",
    "                # 再加一点抖动，若仍失败，给一个大负惩罚引导优化器离开\n",
    "                eps = 1e-8\n",
    "                try:\n",
    "                    L = np.linalg.cholesky(Sigma_sub + np.eye(len(cols_obs)) * eps)\n",
    "                except np.linalg.LinAlgError:\n",
    "                    total_loglik -= 1e6\n",
    "                    continue\n",
    "\n",
    "            Y = X[rows_idx][:, cols_obs]   # 该组没有缺失\n",
    "            centered = Y - mu_sub          # (m, k)\n",
    "            # 批量解 L z^T = centered^T\n",
    "            z = np.linalg.solve(L, centered.T).T  # (m, k)\n",
    "            quad = np.sum(z * z, axis=1)          # 每行的二次型\n",
    "\n",
    "            kdim = len(cols_obs)\n",
    "            logdet = 2.0 * np.sum(np.log(np.diag(L)))  # log|Sigma_sub|\n",
    "            group_ll = -0.5 * (kdim * const_log2pi + logdet + quad)\n",
    "            total_loglik += np.sum(group_ll)\n",
    "\n",
    "        return -total_loglik\n",
    "\n",
    "    # --------- 训练 ---------\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        X: pd.DataFrame，可含缺失\n",
    "        y: pd.Series，可含缺失\n",
    "        \"\"\"\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        if not isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "            y = pd.Series(y)\n",
    "\n",
    "        if isinstance(y, pd.DataFrame):\n",
    "            if y.shape[1] != 1:\n",
    "                raise ValueError(\"y must be a 1-D vector or single-column DataFrame.\")\n",
    "            y = y.iloc[:, 0]\n",
    "\n",
    "        self.feature_names = list(X.columns)\n",
    "        self.target_name = y.name if y.name is not None else \"target\"\n",
    "\n",
    "        # 组合联合数据，列顺序：X 列 + y\n",
    "        data_df = pd.concat([X.reset_index(drop=True),\n",
    "                             y.reset_index(drop=True).rename(self.target_name)],\n",
    "                            axis=1)\n",
    "        n_vars = data_df.shape[1]  # p + 1\n",
    "\n",
    "        # ---- 初始值（pairwise deletion） ----\n",
    "        initial_mu = data_df.mean(axis=0).values  # 忽略 NaN\n",
    "        # DataFrame.cov() 默认 pairwise deletion\n",
    "        initial_sigma_df = data_df.cov()\n",
    "        # 若有全缺列导致 NaN，做点兜底\n",
    "        initial_sigma_df = initial_sigma_df.reindex(index=data_df.columns,\n",
    "                                                    columns=data_df.columns)\n",
    "        if initial_sigma_df.isnull().values.any():\n",
    "            # 用列方差/协方差的简单填充做个可行初值\n",
    "            fill_val = np.nanmean(initial_sigma_df.values)\n",
    "            initial_sigma_df = initial_sigma_df.fillna(fill_val if not np.isnan(fill_val) else 0.0)\n",
    "\n",
    "        # 确保正定\n",
    "        initial_sigma = initial_sigma_df.values.copy()\n",
    "        try:\n",
    "            np.linalg.cholesky(initial_sigma)\n",
    "        except np.linalg.LinAlgError:\n",
    "            initial_sigma = initial_sigma + np.eye(n_vars) * 1e-6\n",
    "\n",
    "        initial_sigma_elems = self._flatten_sigma_upper(initial_sigma)\n",
    "        initial_params_flat = np.concatenate([initial_mu, initial_sigma_elems])\n",
    "\n",
    "        # ---- 预缓存数据与分组（提速关键） ----\n",
    "        self._X_joint = data_df.values  # (N, d)\n",
    "        self._mask_groups = self._build_mask_groups(self._X_joint)\n",
    "\n",
    "        # ---- 最优化（BFGS） ----\n",
    "        result = minimize(\n",
    "            fun=self._neg_log_likelihood,\n",
    "            x0=initial_params_flat,\n",
    "            args=(n_vars,),\n",
    "            method=\"BFGS\",\n",
    "            options={\"maxiter\": 200, \"disp\": False}\n",
    "        )\n",
    "\n",
    "        if not result.success:\n",
    "            print(f\"[Warn] FIML optimization did not fully converge: {result.message}\")\n",
    "\n",
    "        est_params = result.x\n",
    "        est_mu = est_params[:n_vars]\n",
    "        est_sigma = self._unflatten_sigma_upper(est_params[n_vars:], n_vars)\n",
    "\n",
    "        self.est_mu = est_mu\n",
    "        self.est_sigma = est_sigma\n",
    "\n",
    "        # ---- 由联合矩推回回归系数 ----\n",
    "        # 约定 y 在最后一列\n",
    "        idx_y = n_vars - 1\n",
    "        idx_X = np.arange(0, n_vars - 1)\n",
    "\n",
    "        mu_X = est_mu[idx_X]                     # (p,)\n",
    "        mu_y = est_mu[idx_y]                     # scalar\n",
    "        Sigma_XX = est_sigma[np.ix_(idx_X, idx_X)]  # (p, p)\n",
    "        Sigma_yX = est_sigma[idx_y, idx_X][None, :]  # (1, p)\n",
    "\n",
    "        # 逆/解线性方程\n",
    "        Sigma_XX_inv = np.linalg.inv(Sigma_XX)\n",
    "        beta_row = Sigma_yX @ Sigma_XX_inv       # (1, p)\n",
    "\n",
    "        self.beta_coeffs = beta_row.ravel()      # (p,)\n",
    "        self.beta_0 = float(mu_y - beta_row @ mu_X)\n",
    "\n",
    "        return self\n",
    "\n",
    "    # --------- 预测 ---------\n",
    "    def predict(self, X_new):\n",
    "        \"\"\"\n",
    "        X_new: pd.DataFrame（不应再包含缺失；至少应包含训练时的所有列）\n",
    "        return: np.ndarray shape (n_samples,)\n",
    "        \"\"\"\n",
    "        if self.beta_0 is None or self.beta_coeffs is None:\n",
    "            raise RuntimeError(\"Model has not been fitted. Call fit() first.\")\n",
    "\n",
    "        if not isinstance(X_new, pd.DataFrame):\n",
    "            X_new = pd.DataFrame(X_new, columns=self.feature_names)\n",
    "        # 保证列顺序一致\n",
    "        X_ord = X_new[self.feature_names]\n",
    "        return self.beta_0 + X_ord.values @ self.beta_coeffs\n",
    "# ===== END OF REPLACEMENT BLOCK =====\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
